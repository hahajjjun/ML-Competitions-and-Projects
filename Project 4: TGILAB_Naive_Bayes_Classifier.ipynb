{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project 4: TGILAB_Naive_Bayes_Classifier.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMCiIAwuOMGseBj0lQedzAG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hahajjjun/Machine_Learning_Toy_Projects/blob/main/Project_4_TGILAB_Naive_Bayes_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting.py"
      ],
      "metadata": {
        "id": "RRCXoe9PxlwB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RhggdMr71apT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import random\n",
        "from sklearn.datasets import load_iris\n",
        "X,y = load_iris(return_X_y=True)\n",
        "iris_df = pd.DataFrame(X)\n",
        "iris_df['output'] = y\n",
        "iris_df.columns = ['Sepal Length', 'Sepal Width', 'Petal Length', 'Petal Width', 'output']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split2Separate.py"
      ],
      "metadata": {
        "id": "8EKbR4a7UT3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/Test Split\n",
        "def splitDataset(dataset, splitRatio):\n",
        "  trainSize = int(len(dataset) * splitRatio)\n",
        "  index = random.sample(range(len(dataset)), trainSize)\n",
        "  trainSet = dataset.iloc[index]\n",
        "  testSet = dataset.drop(index, axis = 0)\n",
        "  return trainSet, testSet"
      ],
      "metadata": {
        "id": "ygPHace4WwLL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def separate_by_class(dataset):\n",
        "  separated = dict()\n",
        "  for i in range(len(dataset)):\n",
        "    vector = dataset.iloc[i,:]\n",
        "    target = vector[-1]\n",
        "    if target not in separated:\n",
        "      separated[target] = list()\n",
        "    separated[target].append(vector)\n",
        "  return separated"
      ],
      "metadata": {
        "id": "pGtZN079Feur"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = splitDataset(iris_df, 0.8)\n",
        "train_df = train_df.sort_index(axis = 0)\n",
        "test_df = test_df.sort_index(axis = 0)"
      ],
      "metadata": {
        "id": "6caB8TyCUTWg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stats.py"
      ],
      "metadata": {
        "id": "J7V7CNXqxVpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mean(numbers):\n",
        "  return sum(numbers)/len(numbers)\n",
        "\n",
        "def stdev(numbers):\n",
        "  avg = mean(numbers)\n",
        "  variance = sum([(x-avg)**2 for x in numbers]) / (len(numbers) -1)\n",
        "  return math.sqrt(variance)\n",
        "\n",
        "# python asterisk : unpack containter-type data\n",
        "\n",
        "def summarize(dataset, mode = \"list\"): # 데이터의 mean, stdev를 구함\n",
        "  if mode == \"df\":\n",
        "    summaries = [(mean(dataset[column]), stdev(dataset[column])) for column in dataset.columns]\n",
        "    del summaries[-1] # output 열은 삭제\n",
        "    return summaries\n",
        "  elif mode == \"list\":\n",
        "    summaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)] \n",
        "    del summaries[-1] # output 열은 삭제\n",
        "    return summaries\n",
        "\n",
        "def summarizeByClass(dataset): # class별로 4개 feature(input)의 평균, 표준편차를 구함. 나중에 가우시안 분포를 가정할 때 사용됨\n",
        "  separated = separate_by_class(dataset)\n",
        "  summaries = {}\n",
        "  for classValue, instances in separated.items():\n",
        "    summaries[classValue] = summarize(instances, mode = \"list\")\n",
        "  return summaries"
      ],
      "metadata": {
        "id": "-QDbHLvdxUyL"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Gaussian PDF\n",
        "def calculateProbability(x, mean, stdev):\n",
        "  exponent = math.exp(-(x-mean)**2/(2* stdev**2))\n",
        "  return (1/(math.sqrt(2*math.pi)*stdev))*exponent\n",
        "\n",
        "def calculateClassProbabilities(summaries, inputVector):\n",
        "  probabilities = {}\n",
        "  for classValue, classSummaries in summaries.items():\n",
        "    probabilities[classValue] = 1\n",
        "    for i in range(len(classSummaries)):\n",
        "      mean, stdev = classSummaries[i]\n",
        "      x = inputVector[i]\n",
        "      probabilities[classValue] *= calculateProbability(x, mean, stdev) # Naive Assumption applied\n",
        "  return probabilities # inputVector x = (x1, x2, ..., xn)을 넣으면 class별로 P(X=x|Y=y)P(Y=y)=P(X=x^Y=y) 를 구해줌"
      ],
      "metadata": {
        "id": "R_tO9hd1NpPj"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run.py"
      ],
      "metadata": {
        "id": "e3zrYNUyuvsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(summaries, inputVector):\n",
        "  probabilities = calculateClassProbabilities(summaries, inputVector)\n",
        "  bestLabel = None\n",
        "  bestProb =  -1\n",
        "  for classValue, probability in probabilities.items(): # probabilities = {'class1' : 0.01, 'class2' : 0.02, ... , 'classN' : 0.01} 이런 식으로 구성됨. argmax class를 찾는 과정\n",
        "    if (bestLabel is None) or (probability > bestProb):\n",
        "      bestProb = probability\n",
        "      bestLabel = classValue\n",
        "  return bestLabel"
      ],
      "metadata": {
        "id": "-Qjzpg6LWbqM"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getPredictions(summaries, testSet):\n",
        "  predictions = []\n",
        "  for i in range(len(testSet)):\n",
        "    result = predict(summaries, testSet.iloc[i])\n",
        "    predictions.append(result)\n",
        "  return predictions"
      ],
      "metadata": {
        "id": "sEPN3AG0Ws5g"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getAccuracy(testSet, predictions):\n",
        "\tcorrect = 0\n",
        "\tfor x in range(len(testSet)):\n",
        "\t\tif testSet.iloc[x][-1] == predictions[x]:\n",
        "\t\t\tcorrect += 1\n",
        "\treturn (correct/float(len(testSet)))*100.0"
      ],
      "metadata": {
        "id": "C8wGnc_juS6g"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare model\n",
        "summaries = summarizeByClass(train_df)\n",
        "#test model\n",
        "predictions = getPredictions(summaries, test_df)\n",
        "accuracy = getAccuracy(test_df, predictions)\n",
        "\n",
        "print('Accuracy: {0}%'.format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4MeGI0RuWnS",
        "outputId": "acccf961-4266-4e61-f515-df9416d75e89"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 96.66666666666667%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TFTable = pd.DataFrame()\n",
        "TFTable['answer'] = test_df['output']\n",
        "TFTable['prediction'] = predictions\n",
        "TFTable"
      ],
      "metadata": {
        "id": "5RT7fQMyyzrm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
